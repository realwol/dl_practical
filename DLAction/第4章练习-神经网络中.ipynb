{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 神经网络编程练习中\n",
    "\n",
    "本章我们会逐步完成：\n",
    "* 编码实现Dropout传播；\n",
    "* 编码组合Affine-ReLU-Dropout层；\n",
    "* 编码实现Dropout神经网络；\n",
    "* 解耦神经网络；\n",
    "* 正则化比较实验。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from classifiers.chapter4 import *\n",
    "from utils import *\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" 返回相对误差 \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 载入预处理后的数据\n",
    "data = get_CIFAR10_data()\n",
    "for k, v in data.iteritems():\n",
    "  print '%s: ' % k, v.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout 前向传播\n",
    "打开`classifiers\\chapter4\\dropout_layer.py`文件，完成dropout_forward任务。\n",
    "\n",
    "当你完成编码工作，执行下列代码块进行检验。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from classifiers.chapter4.dropout_layers import *\n",
    "x = np.random.randn(500, 500) + 10\n",
    "\n",
    "for p in [0.3, 0.6, 0.75]:\n",
    "  out, _ = dropout_forward(x, {'mode': 'train', 'p': p})\n",
    "  out_test, _ = dropout_forward(x, {'mode': 'test', 'p': p})\n",
    "\n",
    "  print '测试概率 p = ', p\n",
    "  print '均值输入: ', x.mean()\n",
    "  print '训练阶段输出均值: ', out.mean()\n",
    "  print '测试阶段输出均值: ', out_test.mean()\n",
    "  print '训练阶段输出为0的平均个数: ', (out == 0).mean()\n",
    "  print '测试阶段输出为0的平均个数: ', (out_test == 0).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout 反向传播\n",
    "打开`classifiers\\chapter4\\dropout_layer.py`文件，完成dropout_backward任务。\n",
    "\n",
    "当你完成编码工作后，执行下列代码块进行检验："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from utils import *\n",
    "x = np.random.randn(10, 10) + 10\n",
    "dout = np.random.randn( * x.shape )\n",
    "\n",
    "dropout_param = { 'mode': 'train', 'p': 0.8, 'seed': 123 }\n",
    "out, cache = dropout_forward( x, dropout_param )\n",
    "dx = dropout_backward( dout, cache )\n",
    "dx_num = eval_numerical_gradient_array( lambda xx: \n",
    "                                       dropout_forward( xx, dropout_param)[0], x, dout)\n",
    "\n",
    "print 'dx 相对误差: ', rel_error( dx, dx_num )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout全连接神经网络\n",
    "接下来,我们将Dropout功能添加到深层全连接神经网络中，打开`classifiers\\chapter4\\fc_net.py`文件，完成相应的编码任务。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N, D, H1, H2, C = 2, 15, 20, 30, 10\n",
    "X = np.random.randn(N, D)\n",
    "y = np.random.randint(C, size=(N,))\n",
    "\n",
    "for dropout in [0, 0.2, 0.5,0.7]:\n",
    "  print '检验 dropout率 = ', dropout\n",
    "  model = FullyConnectedNet(input_dim=D,hidden_dims=[H1, H2],  num_classes=C,\n",
    "                            weight_scale=5e-2, dropout=dropout, seed=13)\n",
    "\n",
    "  loss, grads = model.loss(X, y)\n",
    "  print '初始化 loss: ', loss\n",
    "\n",
    "  for name in sorted(grads):\n",
    "    f = lambda _: model.loss(X, y)[0]\n",
    "    grad_num = eval_numerical_gradient(f, model.params[name], verbose=False, h=1e-5)\n",
    "    print '%s 相对误差: %.2e' % (name, rel_error(grad_num, grads[name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# trainer\n",
    "\n",
    "解耦神经网络训练过程，打开`chapter4\\trainer.py`阅读相关内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "trainer = None\n",
    "\n",
    "D,H,C,std,r= 3*32*32,200,10,1e-2,0.6\n",
    "model = FullyConnectedNet(input_dim=D, hidden_dims=[H], num_classes=C, weight_scale=std)\n",
    "trainer = Trainer(model,data,update_rule='sgd',\n",
    "                updater_config={'learning_rate': 1e-3,},\n",
    "                lr_decay=0.95,num_epochs=20, batch_size=200,print_every=200)\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 可视化训练/验证结果\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(trainer.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(trainer.train_acc_history, '-o', label='train')\n",
    "plt.plot(trainer.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(trainer.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 正则化实验\n",
    "\n",
    "使用500训练数据进行正则化实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_train = 500\n",
    "small_data = {\n",
    "  'X_train': data['X_train'][:num_train],\n",
    "  'y_train': data['y_train'][:num_train],\n",
    "  'X_val': data['X_val'],\n",
    "  'y_val': data['y_val'],\n",
    "}\n",
    "\n",
    "solvers = {}\n",
    "dropout_choices = [0, 0.3,0.7]\n",
    "for dropout in dropout_choices:\n",
    "  model = FullyConnectedNet(hidden_dims=[600], dropout=dropout)\n",
    "  print \"dropout激活概率(0表示不使用dropout)%f:\"%dropout\n",
    "\n",
    "  trainer = Trainer(model, small_data,\n",
    "                  num_epochs=30, batch_size=100,\n",
    "                  update_rule='sgd',\n",
    "                  updater_config={\n",
    "                    'learning_rate': 5e-4,\n",
    "                  },\n",
    "                  verbose=True, print_every=200)\n",
    "  trainer.train()\n",
    "  solvers[dropout] = trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_accs = []\n",
    "val_accs = []\n",
    "for dropout in dropout_choices:\n",
    "  solver = solvers[dropout]\n",
    "  train_accs.append(solver.train_acc_history[-1])\n",
    "  val_accs.append(solver.val_acc_history[-1])\n",
    "\n",
    "plt.subplot(3, 1, 1)\n",
    "for dropout in dropout_choices:\n",
    "  plt.plot(solvers[dropout].train_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Train accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "  \n",
    "plt.subplot(3, 1, 2)\n",
    "for dropout in dropout_choices:\n",
    "  plt.plot(solvers[dropout].val_acc_history, 'o', label='%.2f dropout' % dropout)\n",
    "plt.title('Val accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(ncol=2, loc='lower right')\n",
    "\n",
    "plt.gcf().set_size_inches(15, 15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = None\n",
    "trainer = None\n",
    "\n",
    "D,C,std,r= 3*32*32,10,1e-2,0.6\n",
    "model = FullyConnectedNet(input_dim=D, hidden_dims=[100,50], num_classes=C, weight_scale=std, dropout=0.7)\n",
    "trainer = Trainer(model,data,update_rule='sgd',\n",
    "                updater_config={'learning_rate': 1e-3,},\n",
    "                lr_decay=0.95,num_epochs=50, batch_size=500,print_every=300)\n",
    "trainer.train()\n",
    "# 可视化训练/验证结果\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.title('Training loss')\n",
    "plt.plot(trainer.loss_history, 'o')\n",
    "plt.xlabel('Iteration')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.title('Accuracy')\n",
    "plt.plot(trainer.train_acc_history, '-o', label='train')\n",
    "plt.plot(trainer.val_acc_history, '-o', label='val')\n",
    "plt.plot([0.5] * len(trainer.val_acc_history), 'k--')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='lower right')\n",
    "plt.gcf().set_size_inches(15, 12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
